{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLHo18QzIvSo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9y-vR_HAIgH_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/My Drive/Data/dataset.zip\" /content/\n",
    "!unzip dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M61ZZOH2MKaO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install spectral\n",
    "!pip install pysptools\n",
    "!pip install scikit-plot\n",
    "!pip install pygco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPNxAMPjJ7Mq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!sudo apt-get -y install python-pip\n",
    "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sExQ_18RMIQA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import spectral as spy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "import shutil\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uT6VS19bIgIV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def list2array(X,isdata=True):\n",
    "    if isdata:\n",
    "        Y = np.zeros(shape=(1,X[0].shape[1]))\n",
    "        for k in range(len(X)):\n",
    "            Y = np.vstack((Y,X[k]))\n",
    "        Y = np.delete(Y,(0),axis=0)\n",
    "    else:\n",
    "        Y = np.zeros(shape=(1,))\n",
    "        for k in range(len(X)):\n",
    "            Y = np.vstack((Y,X[k]))\n",
    "        Y = np.delete(Y,(0),axis=0)\n",
    "    return Y\n",
    "\n",
    "indianpines_class_names = ['background',\n",
    "                           'alfalfa',           'corn-notill',               'corn-min',               'corn',\n",
    "                           'grass/pasture',     'grass/trees',    'grass/pasture-mowed',      'hay-windrowed',\n",
    "                           'oats',          'soybeans-notill',           'soybeans-min',      'soybean-clean',\n",
    "                           'wheat',                   'woods', 'bldg-grass-tree-drives', 'stone-steel towers']\n",
    "\n",
    "def bar_plot(df):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.countplot(x='class', data=df[['class']])\n",
    "    for p in ax.patches:\n",
    "        ax.annotate('{:.1f}%'.format(100 * p.get_height() / df.shape[0]), (p.get_x() + 0.1, p.get_height() + 5))\n",
    "    plt.ylabel('Class count with percentage', fontsize=14)\n",
    "    plt.xlabel('class', fontsize=14)\n",
    "    plt.title('Bar Plot', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "def box_plot(n, df):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.boxplot(x=df[\"class\"], y=df['band-' + str(n)], width=0.3);\n",
    "    plt.title('Box Plot', fontsize=16)\n",
    "    plt.xlabel('Class', fontsize=14)\n",
    "    plt.ylabel(f'Band-{n}', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def distribution_plot(n, df):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.distplot(df['band-' + str(n)], color='mediumSpringGreen', bins=100, hist_kws={'alpha': 0.4});\n",
    "    plt.xlabel('Band - ' + str(n), fontsize=14)\n",
    "    plt.title('Distribution Plot of Band - ' + str(n), fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title='Confusion Matrix',\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized Confusion Matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(f'{title}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def classification_pipeline(classifier,X_train,y_train,X_test,y_test,data_all, width,height,num_classes,test_indices, train_indices, num_train_each_class, model_selection=False):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    data_all = scaler.transform(data_all)\n",
    "\n",
    "    if classifier==\"KNN\":\n",
    "        start_time = time.time()\n",
    "        if model_selection==True:\n",
    "            Clf = KNeighborsClassifier()\n",
    "            param_grid = {'n_neighbors':[3,5,7,9]}\n",
    "            nfolds=10\n",
    "            best_params = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "            print(\"KNN\")\n",
    "            print(\"The parameter grid is:\")\n",
    "            print(param_grid)\n",
    "            print(\"The best parameter is:\")\n",
    "            print(best_params)\n",
    "            KNN = KNeighborsClassifier(n_neighbors=best_params['n_neighbors']).fit(X_train,y_train)\n",
    "\n",
    "        if model_selection==False:\n",
    "            Clf = KNeighborsClassifier()\n",
    "            param_grid = {'n_neighbors':[9]}\n",
    "            nfolds=10\n",
    "            best_params, KNN = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "        Cla_Map = KNN.predict(data_all).reshape(width,height).astype(int).transpose(1,0)\n",
    "        predict_prob = KNN.predict_proba(data_all)\n",
    "        print('(KNN) Train_Acc=%.3f, Test_Cla_Acc=%.3f, (Time_cost=%.3f)'\n",
    "         % (KNN.score(X_train,y_train),KNN.score(X_test,y_test), (time.time()-start_time)))\n",
    "        y1 = KNN.predict(X_test)\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y1)}%')\n",
    "        print(\"KNN Class Report: \\n\",classification_report(y_test,y1))\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plot_confusion_matrix(y_test, y1, classes=indianpines_class_names, normalize= True, title='KNN Confusion Matrix')\n",
    "        prob = KNN.predict_proba(X_test)\n",
    "        skplt.metrics.plot_roc(y_test, prob,title='KNN ROC Curves',  figsize=(15,15))\n",
    "\n",
    "        pre = y1\n",
    "        clmap = [0]*X.shape[0]\n",
    "        for i in range(len(train_indices)):\n",
    "            clmap[train_indices[i]] = y[train_indices[i]]\n",
    "\n",
    "        for i in range(len(test_indices)):\n",
    "            clmap[test_indices[i]] = pre[i]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.array(clmap).reshape((145, 145)), cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.title('Classification Map (KNN)')\n",
    "        plt.savefig('KNN_classification_map.png')\n",
    "        plt.show()\n",
    "        cla_accuracy = KNN.score(X_test,y_test)\n",
    "\n",
    "\n",
    "    if classifier==\"RBF-SVM\":\n",
    "        start_time = time.time()\n",
    "        if model_selection==True:\n",
    "            Clf = SVC(probability=True)\n",
    "            param_grid = {'C':[2**(-9),2**(-8),2**(-7),2**(-6),2**(-5),2**(-4),2**(-3),2**(-2),\n",
    "                               2**(-1),2**(0),2**(1),2**(2),2**(3),2**(4),2**(5),2**(6),2**(7),2**(8),2**(9), 100],\n",
    "                         'gamma': ['scale']\n",
    "                         }\n",
    "            nfolds=10\n",
    "            best_params = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "            print(\"RBF_SVM\")\n",
    "            print(\"The parameter grid is:\")\n",
    "            print(param_grid)\n",
    "            print(\"The best parameter is:\")\n",
    "            print(best_params)\n",
    "            SVM = SVC(C=best_params['C'],probability=True, gamma='scale').fit(X_train, y_train)\n",
    "\n",
    "        if model_selection==False:\n",
    "            Clf = SVC(probability=True)\n",
    "            param_grid = {'C':[2**(5)],\n",
    "                          'gamma': ['scale']\n",
    "                          }\n",
    "            nfolds=10\n",
    "            best_params, SVM = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "\n",
    "        Cla_Map = SVM.predict(data_all).reshape(width,height).astype(int).transpose(1,0)\n",
    "        predict_prob = SVM.predict_proba(data_all)\n",
    "\n",
    "        print('(RBF_SVM) Train_Acc=%.3f, Test_Cla_Acc=%.3f,(Time_cost=%.3f)' %\n",
    "              (SVM.score(X_train,y_train),SVM.score(X_test,y_test), (time.time()-start_time)))\n",
    "        y1 = SVM.predict(X_test)\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y1)}%')\n",
    "        print(\"RBF_SVM Class Report: \\n\",classification_report(y_test,y1))\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plot_confusion_matrix(y_test, y1, classes=indianpines_class_names, normalize = True,title= 'RBF_SVM Confusion_Matrix')\n",
    "        prob =SVM.predict_proba(X_test)\n",
    "        skplt.metrics.plot_roc(y_test, prob, title='RBF_SVM ROC Curves',  figsize=(15,15))\n",
    "\n",
    "        pre = y1\n",
    "        clmap = [0]*X.shape[0]\n",
    "        for i in range(len(train_indices)):\n",
    "            clmap[train_indices[i]] = y[train_indices[i]]\n",
    "\n",
    "        for i in range(len(test_indices)):\n",
    "            clmap[test_indices[i]] = pre[i]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.array(clmap).reshape((145, 145)), cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.title('Classification Map (RBF_SVM)')\n",
    "        plt.savefig('RBF-SVM_classification_map.png')\n",
    "        plt.show()\n",
    "        cla_accuracy = SVM.score(X_test,y_test)\n",
    "\n",
    "    if classifier==\"Poly-SVM\":\n",
    "        start_time = time.time()\n",
    "        if model_selection==True:\n",
    "            Clf = SVC(probability=True)\n",
    "            param_grid = {'C':[2**(-9),2**(-8),2**(-7),2**(-6),2**(-5),2**(-4),2**(-3),2**(-2),\n",
    "                               2**(-1),2**(0),2**(1),2**(2),2**(3),2**(4),2**(5),2**(6),2**(7),2**(8),2**(9)],\n",
    "                         'gamma': ['scale'],\n",
    "                          'kernel': ['poly'],\n",
    "                          'degree': [ 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "                         }\n",
    "            nfolds=10\n",
    "            best_params = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "            print(\"Poly_SVM\")\n",
    "            print(\"The parameter grid is:\")\n",
    "            print(param_grid)\n",
    "            print(\"The best parameter is:\")\n",
    "            print(best_params)\n",
    "            SVM = SVC(C=best_params['C'],probability=True).fit(X_train, y_train)\n",
    "\n",
    "        if model_selection==False:\n",
    "            Clf = SVC(probability=True)\n",
    "            param_grid = {'C':[1000],\n",
    "                          'gamma': ['scale'],\n",
    "                          'kernel': ['poly'],\n",
    "                          'degree': [2],\n",
    "                          }\n",
    "            nfolds=10\n",
    "            best_params, SVM = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "\n",
    "        Cla_Map = SVM.predict(data_all).reshape(width,height).astype(int).transpose(1,0)\n",
    "        predict_prob = SVM.predict_proba(data_all)\n",
    "\n",
    "        print('(Poly_SVM) Train_Acc=%.3f, Test_Cla_Acc=%.3f,(Time_cost=%.3f)'\n",
    "              % (SVM.score(X_train,y_train),SVM.score(X_test,y_test),\n",
    "                  (time.time()-start_time)))\n",
    "        y1 = SVM.predict(X_test)\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y1)}%')\n",
    "        print(\"Poly SVM Class Report: \\n\", classification_report(y_test,y1))\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plot_confusion_matrix(y_test, y1, classes=indianpines_class_names, normalize = True, title= 'Poly_SVM Confusion Matrix')\n",
    "        prob = SVM.predict_proba(X_test)\n",
    "        skplt.metrics.plot_roc(y_test, prob, title='Poly_SVM ROC Curves',  figsize=(15,15))\n",
    "\n",
    "        pre = y1\n",
    "        clmap = [0]*X.shape[0]\n",
    "        for i in range(len(train_indices)):\n",
    "            clmap[train_indices[i]] = y[train_indices[i]]\n",
    "\n",
    "        for i in range(len(test_indices)):\n",
    "            clmap[test_indices[i]] = pre[i]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.array(clmap).reshape((145, 145)), cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.title('Classification Map (Poly SVM)')\n",
    "        plt.savefig('Poly-SVM_classification_map.png')\n",
    "        plt.show()\n",
    "        cla_accuracy = SVM.score(X_test,y_test)\n",
    "\n",
    "    if classifier==\"Xgboost\":\n",
    "        start_time = time.time()\n",
    "        if model_selection==True:\n",
    "            Clf = xgb.XGBClassifier()\n",
    "            param_grid = {'objective': ['multi:softmax'],\n",
    "                      'num_class': [16],\n",
    "                      'tree_method': ['auto'],\n",
    "                      'eta': [0.1],\n",
    "                      'gamma': [0],\n",
    "                      'min_child_weight': [10],\n",
    "                      'colsample_bytree': [1],\n",
    "                      'subsample': [1],\n",
    "                      'max_depth': [10],\n",
    "                      'n_estimator': [3000],\n",
    "                      'nthreads': [-1],\n",
    "                      }\n",
    "            nfolds = 10\n",
    "            best_params = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "            print(\"Xgboost\")\n",
    "            print(\"The parameter grid is:\")\n",
    "            print(param_grid)\n",
    "            print(\"The best parameter is:\")\n",
    "            print(best_params)\n",
    "            XG = xgb.XGBClassifier(max_depth=best_params['max_depth'], objective='multi:softmax', learning_rate=0.1, gamma=best_params['gamma'],\n",
    "                                   tree_method='auto', n_estimators=best_params['n_estimator'],min_child_weight=best_params['min_child_weight']).fit(X_train,y_train)\n",
    "\n",
    "        if model_selection==False:\n",
    "            Clf = xgb.XGBClassifier()\n",
    "            param_grid = {'objective': ['multi:softmax'],\n",
    "                          'num_class': [16],\n",
    "                          'tree_method': ['auto'],\n",
    "                          'eta': [0.1],\n",
    "                          'gamma': [0],\n",
    "                          'min_child_weight': [10],\n",
    "                          'colsample_bytree': [1],\n",
    "                          'subsample': [1],\n",
    "                          'max_depth': [10],\n",
    "                          'n_estimator': [3000],\n",
    "                          'nthreads': [-1],\n",
    "                          }\n",
    "            nfolds=10\n",
    "            best_params, XG = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "\n",
    "        Cla_Map = XG.predict(data_all).reshape(width,height).astype(int).transpose(1,0)\n",
    "        predict_prob = XG.predict_proba(data_all)\n",
    "\n",
    "        print('(Xgboost) Train_Acc=%.3f, Test_Cla_Acc=%.3f, (Time_cost=%.3f)'% (XG.score(X_train,y_train),XG.score(X_test,y_test),\n",
    "                                                                                                   (time.time()-start_time)))\n",
    "        y1 = XG.predict(X_test)\n",
    "        print(\"Xgboost Class Report: \\n\",classification_report(y_test,y1))\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y1)}%')\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plot_confusion_matrix(y_test, y1, classes=indianpines_class_names, normalize = True, title='Xgboost Confusion Matrix')\n",
    "        prob = XG.predict_proba(X_test)\n",
    "        skplt.metrics.plot_roc(y_test, prob, title='Xgboost ROC Curves',  figsize=(15,15))\n",
    "\n",
    "        pre = y1\n",
    "        clmap = [0]*X.shape[0]\n",
    "        for i in range(len(train_indices)):\n",
    "            clmap[train_indices[i]] = y[train_indices[i]]\n",
    "\n",
    "        for i in range(len(test_indices)):\n",
    "            clmap[test_indices[i]] = pre[i]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.array(clmap).reshape((145, 145)), cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.title('Classification Map (XgBoost)')\n",
    "        plt.savefig('XgBoost_classification_map.png')\n",
    "        plt.show()\n",
    "        cla_accuracy = XG.score(X_test,y_test)\n",
    "\n",
    "\n",
    "    if classifier==\"RF\":\n",
    "        start_time = time.time()\n",
    "        if model_selection==True:\n",
    "            Clf = RandomForestClassifier()\n",
    "            param_grid = {'n_estimators':[5,10,20,50,100,200,300,400,500,600,700],\n",
    "                           'min_samples_split': [2,5,10, 15, 20, 25, 30,35, 40,100 ],\n",
    "                         'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10]}\n",
    "            nfolds=10\n",
    "            best_params = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "            print(\"Random Forest\")\n",
    "            print(\"The parameter grid is:\")\n",
    "            print(param_grid)\n",
    "            print(\"The best parameter is:\")\n",
    "            print(best_params)\n",
    "            RF = RandomForestClassifier(n_estimators=best_params['n_estimators']).fit(X_train,y_train)\n",
    "        if model_selection==False:\n",
    "            Clf = RandomForestClassifier()\n",
    "            param_grid = {'n_estimators':[300],\n",
    "                          'min_samples_split': [20],\n",
    "                          'min_samples_leaf': [6]}\n",
    "            nfolds=10\n",
    "            best_params, RF = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "\n",
    "        Cla_Map = RF.predict(data_all).reshape(width,height).astype(int).transpose(1,0)\n",
    "        predict_prob = RF.predict_proba(data_all)\n",
    "\n",
    "        print('(Random Forest) Train_Acc=%.3f, Test_Cla_Acc=%.3f, (Time_cost=%.3f)'\n",
    "              % (RF.score(X_train,y_train),RF.score(X_test,y_test),\n",
    "                 (time.time()-start_time)))\n",
    "        y1 = RF.predict(X_test)\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y1)}%')\n",
    "        print(\"Random Forest Class Report: \\n\", classification_report(y_test,y1))\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plot_confusion_matrix(y_test, y1, classes=indianpines_class_names, normalize = True, title='Random Forest Confusion Matrix')\n",
    "        prob = RF.predict_proba(X_test)\n",
    "        skplt.metrics.plot_roc(y_test, prob, title='Random Forest ROC Curves',  figsize=(15,15))\n",
    "\n",
    "        pre = y1\n",
    "        clmap = [0]*X.shape[0]\n",
    "        for i in range(len(train_indices)):\n",
    "            clmap[train_indices[i]] = y[train_indices[i]]\n",
    "\n",
    "        for i in range(len(test_indices)):\n",
    "            clmap[test_indices[i]] = pre[i]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.array(clmap).reshape((145, 145)), cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.title('Classification Map (Random Forest)')\n",
    "        plt.savefig('RF_classification_map.png')\n",
    "        plt.show()\n",
    "        cla_accuracy = RF.score(X_test,y_test)\n",
    "\n",
    "    if classifier==\"GB\":\n",
    "        start_time = time.time()\n",
    "        if model_selection==True:\n",
    "            Clf = GradientBoostingClassifier()\n",
    "            param_grid = {'n_estimators':[10,50,100,200,300]}\n",
    "            nfolds=10\n",
    "            best_params = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "            print(\"GB\")\n",
    "            print(\"The parameter grid is:\")\n",
    "            print(param_grid)\n",
    "            print(\"The best parameter is:\")\n",
    "            print(best_params)\n",
    "            GB = GradientBoostingClassifier(n_estimators=best_params['n_estimators']).fit(X_train,y_train)\n",
    "        if model_selection==False:\n",
    "            Clf = GradientBoostingClassifier()\n",
    "            param_grid = {'n_estimators':[300]}\n",
    "            nfolds=10\n",
    "            best_params, GB = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "        Cla_Map = GB.predict(data_all).reshape(width,height).astype(int).transpose(1,0)\n",
    "        predict_prob = GB.predict_proba(data_all)\n",
    "        print('(Gradient Boosting) Train_Acc=%.3f, Test_Cla_Acc=%.3f,(Time_cost=%.3f)'\n",
    "              % (GB.score(X_train,y_train),GB.score(X_test,y_test),\n",
    "                  (time.time()-start_time)))\n",
    "        y1 = GB.predict(X_test)\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y1)}%')\n",
    "        print(\"Gradient Boosting Class Report: \\n\", classification_report(y_test, y1))\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plot_confusion_matrix(y_test, y1, classes=indianpines_class_names, normalize=True,\n",
    "                              title='Gradient Boosting Confusion Matrix')\n",
    "        prob = GB.predict_proba(X_test)\n",
    "        skplt.metrics.plot_roc(y_test, prob, title='GB ROC Curves', figsize=(15,15))\n",
    "\n",
    "        pre = y1\n",
    "        clmap = [0]*X.shape[0]\n",
    "        for i in range(len(train_indices)):\n",
    "            clmap[train_indices[i]] = y[train_indices[i]]\n",
    "\n",
    "        for i in range(len(test_indices)):\n",
    "            clmap[test_indices[i]] = pre[i]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.array(clmap).reshape((145, 145)), cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.title('Classification Map (GB)')\n",
    "        plt.savefig('GB_classification_map.png')\n",
    "        plt.show()\n",
    "        cla_accuracy = GB.score(X_test,y_test)\n",
    "\n",
    "\n",
    "    if classifier==\"MLR\":\n",
    "        start_time = time.time()\n",
    "        if model_selection==True:\n",
    "            Clf = MLPClassifier()\n",
    "            param_grid = {'hidden_layer_sizes':[[50,50],[50,100],[50,200],[100,100],\n",
    "                                                [100,200],[200,100],[200,200],[200,300],\n",
    "                                                [200,500],[300,300],[300,400],[300,500],[400,500],[500,500]]}\n",
    "            nfolds=10\n",
    "            best_params = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "            print(\"MLR\")\n",
    "            print(\"The parameter grid is:\")\n",
    "            print(param_grid)\n",
    "            print(\"The best parameter is:\")\n",
    "            print(best_params)\n",
    "            MLP = MLPClassifier(hidden_layer_sizes=best_params['hidden_layer_sizes']).fit(X_train,y_train)\n",
    "        if model_selection==False:\n",
    "            Clf = MLPClassifier()\n",
    "            param_grid = {'hidden_layer_sizes':[400,500]}\n",
    "            nfolds=10\n",
    "            best_params, MLP = param_selection(Clf, X_train, y_train, param_grid, nfolds)\n",
    "        Cla_Map = MLP.predict(data_all).reshape(width,height).astype(int).transpose(1,0)\n",
    "        predict_prob = MLP.predict_proba(data_all)\n",
    "        print('(MLP) Train_Acc=%.3f, Test_Cla_Acc=%.3f,(Time_cost=%.3f)'\n",
    "              % (MLP.score(X_train,y_train),MLP.score(X_test,y_test),\n",
    "                 (time.time()-start_time)))\n",
    "        y1 = MLP.predict(X_test)\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y1)}%')\n",
    "        print(\"MLR Class Report: \\n\", classification_report(y_test, y1))\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plot_confusion_matrix(y_test, y1, classes=indianpines_class_names, normalize=True,\n",
    "                              title='MLR Confusion Matrix')\n",
    "        prob = MLP.predict_proba(X_test)\n",
    "        skplt.metrics.plot_roc(y_test, prob, title='MLR ROC Curves',  figsize=(15,15))\n",
    "\n",
    "        pre = y1\n",
    "        clmap = [0]*X.shape[0]\n",
    "        for i in range(len(train_indices)):\n",
    "            clmap[train_indices[i]] = y[train_indices[i]]\n",
    "\n",
    "        for i in range(len(test_indices)):\n",
    "            clmap[test_indices[i]] = pre[i]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.array(clmap).reshape((145, 145)), cmap='jet')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.title('Classification Map (MLP)')\n",
    "        plt.savefig('MLP_classification_map.png')\n",
    "        plt.show()\n",
    "        cla_accuracy = MLP.score(X_test,y_test)\n",
    "\n",
    "    return Cla_Map,cla_accuracy,\n",
    "\n",
    "def param_selection(Clf, X_train, y_train, param_grid, nfolds):\n",
    "    grid_search = GridSearchCV(Clf, param_grid, cv=nfolds)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    return best_params, grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "vt1jNHzryyU6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "duY2eiePX5s5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_soil = pd.read_csv(\"/content/dataset/Dataset_hyper.csv\")\n",
    "df_soil.loc[:,'class'].value_counts()\n",
    "X = df_soil.iloc[:, :-1].values\n",
    "y = df_soil.iloc[:, -1].values\n",
    "label_all = y\n",
    "data_all = X\n",
    "data = X\n",
    "label = y \n",
    "print(X.shape, y.shape)\n",
    "height = 145\n",
    "width = 145\n",
    "band = 220\n",
    "num_classes = 16\n",
    "Label = label.reshape(height, width)\n",
    "df_soil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "cXMkqhGTyyVC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "WeLjMSvayyVD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0X0JsbsyyVD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_band(dataset):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    band_no = np.random.randint(dataset.shape[1])\n",
    "    dataset = dataset.values.reshape(145,145,dataset.shape[1])\n",
    "    plt.imshow(dataset[:,:, band_no], cmap='jet')\n",
    "    plt.title(f'Band-{band_no}', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZCblmMMyyVF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_band(df_soil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "EhjYc6USyyVG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing ground truth of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvPx0y0YyyVG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "ground_truth = df_soil['class']\n",
    "ground_truth = ground_truth.values.reshape(145,145)\n",
    "plt.imshow(ground_truth)\n",
    "plt.axis('off')\n",
    "plt.colorbar(ticks= range(0,16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "GQjQR69GyyVH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing Spectral Signatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DXx1xFOyyVI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_signature(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    pixel_no = np.random.randint(df.shape[0])\n",
    "    print(\"Pixel No: \",pixel_no)\n",
    "    plt.plot(range(1, 221), df.iloc[pixel_no, :-1].values.tolist(), 'b--', label= f'Class - {df.iloc[pixel_no, -1]}')\n",
    "    plt.legend()\n",
    "    plt.title(f'Pixel({pixel_no}) signature', fontsize=14)\n",
    "    plt.xlabel('Band Number', fontsize=14)\n",
    "    plt.ylabel('Pixel Intensity', fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJBOnGQ1yyVI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_signature(df_soil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2m9jyxCyyVJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "box_plot(50, df_soil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "0YCTxZXEyyVK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Nv6Z6pT9yyVK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Detecting outliers using the Inter Quantile Range(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crf_QylVyyVK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outliers = []\n",
    "def detect_outliers_iqr(data):\n",
    "    data = sorted(data)\n",
    "    q1 = np.percentile(data, 30)\n",
    "    q3 = np.percentile(data, 70)\n",
    "    # print(q1, q3)\n",
    "    IQR = q3-q1\n",
    "    lwr_bound = q1-(1.5*IQR)\n",
    "    upr_bound = q3+(1.5*IQR)\n",
    "    # print(lwr_bound, upr_bound)\n",
    "    for i in data:\n",
    "        if i<lwr_bound or i>upr_bound:\n",
    "            outliers.append(i)\n",
    "    return outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZ_a97x4yyVL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "band = 50\n",
    "sample_outliers = detect_outliers_iqr(df_soil[f'band-{band}'])\n",
    "median = np.median(df_soil[f'band-{band}'])  # Replace with median\n",
    "d_band = df_soil[f'band-{band}'].copy()\n",
    "for i in sample_outliers:\n",
    "    d_band[d_band == i] = median\n",
    "sns.boxplot(x=df_soil[\"class\"], y=d_band, width=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "WcMGJlIOyyVL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Splitting and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIKrS588BnXq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, train_indexes, test_indexes = \\\n",
    "train_test_split(X, y, range(X.shape[0]),train_size=0.8, random_state=123, stratify=y)\n",
    "train_indices = list2array(train_indexes, isdata=False)\n",
    "test_indices = list2array(test_indexes, isdata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4iXZYXWEGQ2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_data_summary_1(y_train,y_test,y,num_classes):\n",
    "    df = pd.DataFrame(np.random.randn(num_classes, 3),\n",
    "                      index=[indianpines_class_names[i] for i in range(0,num_classes)],\n",
    "                  columns=['Train', 'Test', 'Total'])\n",
    "    df['Train'] = [sum(y_train==i) for i in range(0,num_classes)]\n",
    "    df['Total'] = [sum(y==i) for i in range(0,num_classes)]\n",
    "    df['Test'] = np.array(df['Total']) - np.array(df['Train'])\n",
    "    print('Summary of training and testing samples:')\n",
    "    print(df)\n",
    "    print(\"Training samples: %d\" % len(y_train))\n",
    "    print(\"Test samples: %d\" % len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7z2L8lrByep",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_data_summary_1(y_train, y_test, y, num_classes)\n",
    "num_train_each_class = np.array([np.sum(y_train==i+1) for i in range(num_classes)])\n",
    "print(num_train_each_class.shape)\n",
    "classifiers = [\"KNN\",\"RBF-SVM\",\"Poly-SVM\", \"Xgboost\", \"RF\", \"GB\",\"MLR\"]\n",
    "model_selection = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geGClhYd46mY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Cla_accuracy = np.zeros((np.size(classifiers),1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GvEHiXY_DhBZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(classifiers)):\n",
    "        \n",
    "        classifier = classifiers[i]\n",
    "        Cla_Map,cla_accuracy = classification_pipeline(classifier,X_train,y_train,X_test,y_test,data_all,\n",
    "                                                       width,height,num_classes,test_indexes,train_indexes,\n",
    "                                                       num_train_each_class,model_selection)\n",
    "        Cla_accuracy[i,0] = cla_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iILot85S0sG3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cla_accuracy = np.zeros((np.size(classifiers),1))\n",
    "# Cla_accuracy[i,0] = cla_accuracy\n",
    "Cla_Acc_Mean = np.mean(Cla_accuracy,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vziql82A0Z7c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(np.random.randn(np.size(classifiers),1),index=classifiers,                                 \n",
    "                             columns=['Cla_Acc'])\n",
    "df_result['Cla_Acc'] = Cla_Acc_Mean\n",
    "print(df_result)\n",
    "\n",
    "print('The best classifier for is ' + str(classifiers[Cla_Acc_Mean.argmax()]) + '.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}